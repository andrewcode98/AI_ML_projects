{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deffcf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Data_Processing import preprocessing, modify_target_binary\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, recall_score, accuracy_score\n",
    "from typing import Dict\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2c6786b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_30928\\2285443003.py:1: DtypeWarning: Columns (0,19,49,59,118,129,130,131,134,135,136,139,145,146,147) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  loan_df = pd.read_csv(\"data/accepted_2007_to_2018Q4.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame read!\n"
     ]
    }
   ],
   "source": [
    "loan_df = pd.read_csv(\"data/accepted_2007_to_2018Q4.csv\")\n",
    "print(\"DataFrame read!\")\n",
    "loan_df = modify_target_binary(loan_df, \"loan_status\")\n",
    "# Remove Current/Issued targets before preprocessing\n",
    "loan_df = loan_df.loc[~loan_df[\"loan_status\"].isin([\"Current\",\"Issued\"])].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6fe06e",
   "metadata": {},
   "source": [
    "Training using class weights and Random Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "383c52e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [05:16<00:00,  6.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV F1-score: 0.7016153391753142\n",
      "{'n_estimators': np.int64(300), 'max_depth': np.int64(45), 'min_samples_split': np.int64(2), 'max_features': np.str_('sqrt'), 'min_samples_leaf': np.int64(3), 'class_weight': np.str_('balanced'), 'n_jobs': np.int64(-1)}\n",
      "XGBoost :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [15:26<00:00, 18.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV F1-score: 0.739531258298104\n",
      "{'n_estimators': np.int64(300), 'max_depth': np.int64(10), 'learning_rate': np.float64(0.1), 'objective': np.str_('binary:logistic'), 'subsample': np.float64(0.9), 'colsample_bytree': np.float64(0.5), 'reg_alpha': np.float64(0.8), 'reg_lambda': np.float64(0.05)}\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state= 42)\n",
    "RF_grid_dist =        {\"n_estimators\": [300],\n",
    "                       \"max_depth\" :  np.arange(5, 61, 5),\n",
    "                       \"min_samples_split\" : np.arange(2,21),\n",
    "                       \"max_features\": [\"sqrt\",\"log2\"],\n",
    "                       \"min_samples_leaf\": np.arange(2,21),\n",
    "                       \"class_weight\": [\"balanced\"],\n",
    "                       \"n_jobs\" : [-1]\n",
    "                       }\n",
    "\n",
    "XGBoost_grid_dist = {\"n_estimators\": np.array([300]),\n",
    "                     \"max_depth\": np.arange(5,61,5),\n",
    "                     \"learning_rate\":np.array([0.001, 0.01, 0.1, 0.5]),\n",
    "                     \"objective\": [\"binary:logistic\"],\n",
    "                     \"subsample\": np.arange(0.1, 1.0, 0.1),\n",
    "                     \"colsample_bytree\": np.arange(0.1, 1.0, 0.1),\n",
    "                     \"reg_alpha\": np.array([0.01, 0.05, 0.1, 0.5, 0.8]),\n",
    "                     \"reg_lambda\": np.array([0.01, 0.05, 0.1, 0.5, 0.8])}\n",
    "\n",
    "# Function to perform random search with stratified k-fold validation\n",
    "def RANDOM_SEARCH_CV_SS(param_dist: Dict, n_iterations: int, X_train: pd.DataFrame, y_train: pd.Series, model_classifier, cv:StratifiedKFold):\n",
    "    results = []\n",
    "    best_score = -np.inf\n",
    "    best_params = None\n",
    "\n",
    "    for _ in tqdm(range(n_iterations)):\n",
    "\n",
    "\n",
    "        params = {}\n",
    "        for key,values in param_dist.items():\n",
    "            params[key] = np.random.choice(values)\n",
    "\n",
    "        f1_scores = []\n",
    "        recalls = []\n",
    "        accuracy_scores = []\n",
    "\n",
    "        for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "            X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "            y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "            model = model_classifier(\n",
    "                **params\n",
    "            )\n",
    "\n",
    "            model.fit(X_tr, y_tr)\n",
    "            y_pred = model.predict(X_val)\n",
    "\n",
    "            f1_scores.append(f1_score(y_val, y_pred))\n",
    "            recalls.append(recall_score(y_val, y_pred))\n",
    "            accuracy_scores.append(accuracy_score(y_val, y_pred))\n",
    "\n",
    "        mean_f1 = np.mean(f1_scores)\n",
    "\n",
    "        if mean_f1 > best_score:\n",
    "            best_score = mean_f1\n",
    "            best_model = model\n",
    "            best_params = params\n",
    "\n",
    "    return best_params, best_score, best_model\n",
    "    \n",
    "# Function to tune random forest hyperparameters on sample of data\n",
    "def hyperparameter_tuning(rows_sample:int, df:pd.DataFrame, cv:StratifiedKFold, param_dist:Dict, model_classifier):\n",
    "    df_sample = df.sample(n = rows_sample)\n",
    "    X_sample =  df_sample.drop(columns=\"loan_status\")\n",
    "    y_sample =  df_sample[\"loan_status\"]\n",
    "    X_sample = preprocessing(X_sample)\n",
    "    best_params, best_score, best_model = RANDOM_SEARCH_CV_SS(param_dist, 50, X_sample, y_sample, model_classifier, cv)\n",
    "    print(f\"Best CV F1-score: {best_score}\")\n",
    "    print(best_params)\n",
    "    return best_params, best_score, best_model\n",
    "\n",
    "print(\"Random Forest: \")\n",
    "best_RF_params, best_f1_score, best_RF_model = hyperparameter_tuning(10000, loan_df, skf, RF_grid_dist, RandomForestClassifier)\n",
    "print(\"XGBoost :\")\n",
    "best_XGB_params, best_f1_score, best_XGB_model = hyperparameter_tuning(10000, loan_df, skf, XGBoost_grid_dist, XGBClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c8615e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing finished!\n",
      "XBG model trained!\n",
      "Random Forest trained!\n"
     ]
    }
   ],
   "source": [
    "# Training using best hyperparameters on the whole dataset\n",
    "X = loan_df.drop(columns=[\"loan_status\"])\n",
    "y = loan_df[\"loan_status\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, \n",
    "                                                    random_state = 42, \n",
    "                                                    shuffle = True, \n",
    "                                                    stratify = y)\n",
    "\n",
    "X_train, X_test = preprocessing(X_train), preprocessing(X_test)\n",
    "print(\"Processing finished!\")\n",
    "# XGBoost best params\n",
    "XGB_model = XGBClassifier(**best_XGB_params)\n",
    "XGB_model.fit(X_train,y_train)\n",
    "print(\"XBG model trained!\")\n",
    "# Random Forest best params\n",
    "RF_model = RandomForestClassifier(**best_RF_params)\n",
    "RF_model.fit(X_train,y_train)\n",
    "print(\"Random Forest trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43450dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved!\n"
     ]
    }
   ],
   "source": [
    "# Save the models trained with the best hyperparameters\n",
    "dump(XGB_model, r\"models\\xgb_model_1.joblib\")\n",
    "dump(RF_model,  r\"models\\random_forest_model.joblib\")\n",
    "print(\"Models saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
